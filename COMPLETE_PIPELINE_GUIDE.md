# üîß Complete Content Generation Pipeline - Implementation Guide

## Executive Summary

This document provides a comprehensive specification for the content generation pipeline in Graive AI, transforming the system from a chat-based interface into a true autonomous execution engine. The pipeline implements a structured, multi-stage workflow that ensures professional-quality document creation with embedded media, structured data visualizations, and rigorous quality control.

## Pipeline Architecture Overview

The content generation pipeline operates as a sequential processing system where each stage produces well-defined outputs that serve as inputs to subsequent stages. This architectural pattern ensures data integrity, enables granular error handling, and facilitates iterative quality improvement through targeted revision cycles.

## Stage 1: Request Detection and Routing

### Purpose

The initial stage interprets user natural language input to identify the intended task type, extract relevant parameters, and route the request to the appropriate execution handler. This stage determines whether the system will generate documents, create images, execute code, or engage in conversational interaction.

### Implementation Location

**File**: [graive.py](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\graive.py)  
**Method**: [process_user_request()](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\graive.py#L1165-L1395)  
**Lines**: 1165-1395

### Detection Logic

The system employs keyword-based pattern matching combined with regular expression parsing to extract structured parameters from unstructured text. Detection proceeds in priority order, with more specific task types checked before more general ones to prevent false positive matches.

#### Document Generation Detection

Document generation requests are identified through the presence of write-oriented keywords combined with topic indicators. The enhanced implementation recognizes multiple prepositional patterns to accommodate natural language variation.

```python
write_keywords = ['write', 'generate', 'create', 'make me', 'essay', 'article', 'paper', 'document', 'thesis']
is_write_request = any(keyword in message_lower for keyword in write_keywords)

# Enhanced topic extraction supporting "about", "of", and "on"
if 'about' in message_lower:
    topic_match = re.search(r'about\s+([\w\s]+?)(?:\s+(?:in|with|well|and)|$)', message_lower)
elif 'of' in message_lower:
    topic_match = re.search(r'(?:essay|article|paper|document|thesis)\s+of\s+([\w\s]+?)(?:\s+(?:with|in|and)|$)', message_lower)
elif 'on' in message_lower:
    topic_match = re.search(r'(?:essay|article|paper|document|thesis)\s+on\s+([\w\s]+?)(?:\s+(?:with|in|and)|$)', message_lower)
```

#### Parameter Extraction

Additional document attributes are extracted through keyword presence checks and regex pattern matching:

- **Word Count**: Extracted via `(\d+)\s*words?` pattern, defaults to 1200 if not specified
- **Images**: Boolean flag set when "image" or "picture" appears in request
- **Tables**: Boolean flag set when "table" appears in request
- **Format**: Determined by presence of "docx" keyword, defaults to "md"

### Output Specification

The detection stage produces a structured dictionary containing the action type and all extracted parameters:

```python
{
    'action': 'generate_document',
    'topic': 'japan',
    'word_count': 1200,
    'include_images': True,
    'include_tables': True,
    'format': 'md'
}
```

### Diagnostic Feedback

When document generation is detected, the system displays confirmation of the parsed parameters to provide transparency and enable user verification:

```
[üîç Detection] Document generation detected!
   Topic: japan
   Words: 1200
   Images: True
   Tables: True
```

## Stage 2: Document Structure Planning

### Purpose

Before content generation begins, the system must create a comprehensive structural plan that defines the document's organization, determines optimal section breakdown, identifies locations for media insertion, and establishes the logical flow of information. This planning phase ensures coherent document architecture rather than ad-hoc text assembly.

### Current Implementation Status

**Status**: ‚ö†Ô∏è NEEDS IMPLEMENTATION

The current system proceeds directly from detection to content generation without an intermediate planning stage. This gap should be addressed by implementing a dedicated document planner that analyzes the topic and generates a structured outline.

### Recommended Implementation

#### File Structure

Create new module: `src/planning/document_planner.py`

#### Planner Responsibilities

1. **Outline Generation**: Create hierarchical section structure based on topic and document type
2. **Section Sizing**: Allocate word counts to each section proportional to importance
3. **Media Placement**: Determine optimal locations for images and tables
4. **Citation Strategy**: Plan citation density and distribution
5. **Quality Criteria**: Establish section-specific quality metrics

#### Output Specification

The planner should produce a document blueprint containing:

```python
{
    'title': 'Japan: Tradition and Innovation',
    'sections': [
        {
            'title': 'Introduction',
            'word_count': 200,
            'key_points': ['Overview', 'Thesis statement'],
            'media': []
        },
        {
            'title': 'Geography and Culture',
            'word_count': 300,
            'key_points': ['Physical features', 'Cultural traditions'],
            'media': [{'type': 'image', 'subject': 'Japanese landscape'}]
        },
        {
            'title': 'Economic Development',
            'word_count': 300,
            'key_points': ['Industrial growth', 'Major companies'],
            'media': [{'type': 'table', 'subject': 'Top industries'}]
        },
        {
            'title': 'Cuisine and Hospitality',
            'word_count': 250,
            'key_points': ['Traditional food', 'Omotenashi concept'],
            'media': [{'type': 'image', 'subject': 'Japanese cuisine'}]
        },
        {
            'title': 'Conclusion',
            'word_count': 150,
            'key_points': ['Summary', 'Future outlook'],
            'media': []
        }
    ],
    'total_sections': 5,
    'estimated_citations': 12,
    'image_count': 2,
    'table_count': 1
}
```

## Stage 3: Content Generation with LLM Integration

### Purpose

This stage transforms the document plan into actual prose content, generating professional-quality text for each section while maintaining coherence across the entire document. The content generator interfaces with configured LLM providers to produce human-like writing that addresses the specified key points.

### Current Implementation

**File**: [graive.py](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\graive.py)  
**Method**: [_generate_content_action()](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\graive.py#L743-L813)  
**Lines**: 743-813

### Generation Strategy

The current implementation generates content as a single monolithic block, which limits control over section quality and makes iterative revision challenging. The method constructs a prompt instructing the LLM to produce complete content and uses streaming or batch API calls to retrieve the generated text.

```python
def _generate_content_action(self, topic: str, word_count: int, include_citations: bool) -> Dict[str, Any]:
    prompt = f"""Write a comprehensive, well-researched article about {topic}.

Requirements:
- Target length: {word_count} words
- Use professional academic style
- Include introduction, body sections, and conclusion
- {'Include citations in APA format' if include_citations else 'No citations needed'}
- Use clear section headings
- Provide detailed, factual information

Begin writing:"""
    
    # Call LLM via OpenAI or DeepSeek
    content = self._call_llm_for_content(prompt, max_tokens=word_count * 2)
    
    return {
        "content": content,
        "actual_words": len(content.split())
    }
```

### Recommended Enhancement

#### Section-by-Section Generation

Rather than generating the entire document in one API call, the system should iterate through the planned sections and generate each independently. This approach enables:

- **Granular Quality Control**: Each section can be evaluated and revised individually
- **Progressive Context**: Earlier sections inform later generation through context window
- **Parallel Processing**: Multiple sections can be generated concurrently
- **Error Recovery**: Failures in one section don't invalidate the entire document

#### Implementation Pattern

```python
def generate_document_sections(self, plan: Dict) -> Dict[str, Any]:
    sections_content = []
    
    for section in plan['sections']:
        section_prompt = self._build_section_prompt(
            section_title=section['title'],
            key_points=section['key_points'],
            word_count=section['word_count'],
            context=sections_content  # Previous sections for coherence
        )
        
        section_content = self._call_llm_for_content(section_prompt)
        
        # Quality check before accepting
        quality_score = self.review_system.assess_section_quality(section_content)
        if quality_score < 7.0:
            section_content = self._revise_section(section_content, quality_score)
        
        sections_content.append({
            'title': section['title'],
            'content': section_content,
            'word_count': len(section_content.split()),
            'quality_score': quality_score
        })
    
    return {
        'sections': sections_content,
        'total_words': sum(s['word_count'] for s in sections_content)
    }
```

## Stage 4: Media Generation and Acquisition

### Purpose

Visual elements enhance document comprehension and professional appearance. This stage creates or acquires images, charts, and diagrams specified in the document plan, ensuring all media assets are properly formatted and ready for insertion.

### Current Implementation

**File**: [src/media/image_generator.py](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\src\media\image_generator.py)  
**Lines**: 1-355

### Generation Methods

The image generator supports three distinct generation strategies:

#### 1. Programmatic Generation

Simple graphics like national flags, basic charts, and geometric patterns are created using PIL/Pillow without requiring external API calls. This method is cost-effective and produces consistent results.

```python
def _generate_programmatic(self, description: str, size: str):
    from PIL import Image, ImageDraw
    
    if "japan" in description.lower():
        img = Image.new('RGB', (width, height), 'white')
        draw = ImageDraw.Draw(img)
        # Draw red circle (Japanese flag)
        draw.ellipse([center_x - radius, center_y - radius, 
                     center_x + radius, center_y + radius],
                    fill='#BC002D')
        img.save(filepath)
```

#### 2. Web Download

Stock images and public domain content can be retrieved from sources like Wikimedia Commons, Unsplash, or Pexels through their APIs. This provides access to high-quality photography without generation costs.

#### 3. AI Generation

Complex, custom illustrations are created using DALL-E 3, Stable Diffusion, or other generative AI models. This method enables creation of specific visualizations that don't exist in stock libraries.

```python
def _generate_with_ai(self, description: str, size: str):
    from openai import OpenAI
    client = OpenAI(api_key=openai_key)
    
    response = client.images.generate(
        model="dall-e-3",
        prompt=description,
        size="1024x1024",
        quality="standard"
    )
    
    image_url = response.data[0].url
    # Download and save
```

### Integration with Document Plan

The media generator should process the media specifications from the document plan, creating all required assets before document assembly:

```python
def generate_planned_media(self, media_plan: List[Dict]) -> List[Dict]:
    generated_media = []
    
    for media_spec in media_plan:
        if media_spec['type'] == 'image':
            result = self.image_generator.generate_image(
                description=media_spec['subject'],
                method="auto"
            )
            generated_media.append({
                'type': 'image',
                'path': result['path'],
                'description': media_spec['subject'],
                'placement': media_spec.get('placement', 'inline')
            })
    
    return generated_media
```

## Stage 5: Table Generation and Data Visualization

### Purpose

Structured data must be transformed into readable tables that enhance document informativeness. This stage converts raw data points into formatted tables with proper headers, alignment, and styling.

### Current Implementation

**File**: [graive.py](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\graive.py)  
**Method**: [_generate_table_action()](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\graive.py#L815-L828)  
**Lines**: 815-828

### Current Limitations

The existing implementation generates static placeholder tables rather than deriving content from actual data or generating relevant information through LLM calls:

```python
def _generate_table_action(self, topic: str, table_num: int) -> Dict[str, Any]:
    table_md = f"""| Category | Value | Description |
|----------|-------|-------------|
| Metric 1 | 100   | First data point related to {topic} |
| Metric 2 | 250   | Second data point |
| Metric 3 | 175   | Third data point |
| Metric 4 | 300   | Fourth data point |"""
    
    return {"table_markdown": table_md}
```

### Recommended Enhancement

#### LLM-Generated Tables

Tables should be generated through LLM prompts that request structured data relevant to the document topic:

```python
def generate_table_content(self, table_spec: Dict, topic: str) -> Dict[str, Any]:
    prompt = f"""Generate a professional table about {table_spec['subject']} in the context of {topic}.

Requirements:
- Create {table_spec.get('rows', 5)} rows of data
- Include {table_spec.get('columns', 3)} columns
- Use accurate, relevant data
- Format as Markdown table
- Include descriptive headers

Example:
| Header1 | Header2 | Header3 |
|---------|---------|---------|
| Data1   | Data2   | Data3   |

Generate the table:"""
    
    table_content = self._call_llm_for_content(prompt)
    
    return {
        "table_markdown": table_content,
        "rows": table_content.count('\n') - 1,
        "subject": table_spec['subject']
    }
```

## Stage 6: Document Assembly and Formatting

### Purpose

This stage combines all generated components‚Äîtext sections, images, tables, and citations‚Äîinto a unified document with consistent formatting, proper structure, and professional appearance.

### Current Implementation

**File**: [graive.py](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\graive.py)  
**Method**: [generate_document()](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\graive.py#L462-L667)  
**Lines**: 462-667

### Assembly Process

The document assembler currently concatenates content sections with image and table insertion at predefined points:

```python
# Generate content
content = content_result["content"]

# Add images if requested
if include_images:
    for i in range(num_images):
        img_desc = f"Figure {i+1}: Illustration related to {topic}"
        content += f"\n\n![{img_desc}](images/{safe_topic}_fig{i+1}.png)\n"

# Add tables if requested
if include_tables:
    for i in range(num_tables):
        table_md = self._generate_table_action(topic, i+1)["table_markdown"]
        content += f"\n\n### Table {i+1}: Data for {topic}\n\n{table_md}\n"
```

### Recommended Enhancement

#### Intelligent Media Placement

Rather than appending media at the end, the assembler should insert images and tables at semantically appropriate locations within the text:

```python
def assemble_document(self, sections: List[Dict], media: List[Dict], tables: List[Dict]) -> str:
    document_content = f"# {self.title}\n\n"
    
    for i, section in enumerate(sections):
        # Add section heading and content
        document_content += f"## {section['title']}\n\n"
        document_content += section['content'] + "\n\n"
        
        # Insert media associated with this section
        section_media = [m for m in media if m.get('section_index') == i]
        for media_item in section_media:
            document_content += f"![{media_item['description']}]({media_item['path']})\n\n"
            document_content += f"*Figure {media_item['number']}: {media_item['caption']}*\n\n"
        
        # Insert tables associated with this section
        section_tables = [t for t in tables if t.get('section_index') == i]
        for table in section_tables:
            document_content += f"### Table {table['number']}: {table['title']}\n\n"
            document_content += table['markdown'] + "\n\n"
    
    return document_content
```

### Professional Formatting

For DOCX and PDF outputs, the document formatter applies styling rules:

**File**: [src/formatting/document_formatter.py](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\src\formatting\document_formatter.py)  
**Lines**: 1-393

This module handles:
- Title pages with proper metadata
- Table of contents generation
- Header and footer configuration
- Page numbering
- Image sizing and positioning
- Table styling and borders
- Citation formatting

## Stage 7: Quality Assurance and Review

### Purpose

Before document delivery, comprehensive quality assessment ensures the output meets professional standards across multiple dimensions. This stage evaluates content quality, identifies weaknesses, and triggers revision cycles when necessary.

### Current Implementation

**File**: [src/quality/review_system.py](file://c:\Users\GEMTECH%201\Desktop\GRAIVE\src\quality\review_system.py)  
**Lines**: 1-574

### Quality Dimensions

The PhD-level review system evaluates eight distinct quality dimensions:

1. **Clarity and Readability**: Sentence structure, word choice, accessibility
2. **Logical Coherence**: Argument flow, transitions, reasoning quality
3. **Content Depth**: Analysis thoroughness, detail level, insight quality
4. **Citations and References**: Source integration, citation density, academic rigor
5. **Document Structure**: Organization, section balance, hierarchy appropriateness
6. **Originality and Critical Analysis**: Novel insights, critical thinking depth
7. **Grammar and Language**: Grammatical correctness, academic language use
8. **Academic Tone**: Formality level, objectivity, appropriate hedging

### Scoring and Revision

Each dimension receives a score from 0-10, with the overall quality determined by averaging all dimension scores. Documents scoring below the configured threshold (default 8.0) enter an iterative revision cycle:

```python
def review_content(self, content: str, topic: str) -> Dict[str, Any]:
    scores = []
    
    for dimension in QUALITY_DIMENSIONS:
        score = self._assess_dimension(content, dimension)
        scores.append(score)
    
    avg_score = sum(s.score for s in scores) / len(scores)
    
    if avg_score < self.min_threshold:
        revised_content = self.revise_content(content, scores, topic)
        return self.review_content(revised_content, topic)  # Re-evaluate
    
    return {
        "scores": {s.dimension: s.score for s in scores},
        "average_score": avg_score,
        "quality_level": self._classify_quality(avg_score),
        "needs_revision": False
    }
```

### Integration Point

The review system should be invoked after initial content generation but before media integration:

```python
# Generate content
result = self._generate_content_action(topic, word_count, True)
content = result["content"]

# Review and revise if needed
if enable_phd_review and self.review_system:
    review_report = self.review_system.review_content(content, topic)
    if review_report['needs_revision']:
        content = self.review_system.revise_content(content, review_report, topic)
```

## Stage 8: File Persistence and Session Management

### Purpose

The final stage saves the assembled document to the filesystem within the appropriate session workspace, tracks the file location for future reference, and provides user notification of successful completion.

### Current Implementation

**Session Workspace**: Each conversation receives a unique session folder:

```python
self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
self.session_workspace = self.workspace / f"session_{self.session_id}"
```

**File Writing**: Documents are saved to the session-specific documents subdirectory:

```python
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
safe_topic = re.sub(r'[^\w\s-]', '', topic).strip().replace(' ', '_')
file_name = f"{safe_topic}_{timestamp}.{output_format}"
file_path = str(self.session_workspace / "documents" / file_name)

with open(file_path, 'w', encoding='utf-8') as f:
    f.write(content)
```

**Reference Tracking**: The file path is stored for future operations:

```python
self.last_generated_document = file_path
```

### Workspace Organization

```
workspace/
‚îî‚îÄ‚îÄ session_20251026_142835/
    ‚îú‚îÄ‚îÄ documents/
    ‚îÇ   ‚îú‚îÄ‚îÄ japan_20251026_142905.md
    ‚îÇ   ‚îî‚îÄ‚îÄ climate_20251026_143120.md
    ‚îú‚îÄ‚îÄ images/
    ‚îÇ   ‚îú‚îÄ‚îÄ japanese_landscape.png
    ‚îÇ   ‚îî‚îÄ‚îÄ climate_chart.png
    ‚îú‚îÄ‚îÄ code/
    ‚îÇ   ‚îî‚îÄ‚îÄ data_analyzer.py
    ‚îî‚îÄ‚îÄ data/
        ‚îî‚îÄ‚îÄ raw_data.json
```

## Pipeline Execution Flow

### Complete Workflow Example

For the request "write an essay of japan with an image and a table inside":

```
1. DETECTION PHASE
   Input: "write an essay of japan with an image and a table inside"
   ‚Üì
   [üîç Detection] Document generation detected!
      Topic: japan
      Words: 1200
      Images: True
      Tables: True
   ‚Üì
   Action: generate_document

2. PLANNING PHASE (To Be Implemented)
   ‚Üì
   Document Plan Generated:
   - 5 sections (Intro, Geography, Economy, Culture, Conclusion)
   - 1 image placement (after Geography section)
   - 1 table placement (within Economy section)
   - Target citations: 10-15

3. CONTENT GENERATION
   ‚Üì
   [Step 1/6] Generating initial content via API...
   Provider: OpenAI GPT-3.5-Turbo-16K
   Status: Sending request...
   ‚úÖ Generated 1245 words

4. QUALITY REVIEW
   ‚Üì
   [Step 2/6] PhD-Level Quality Review...
   Conducting multi-dimensional assessment...
   Overall Score: 8.2/10 (GOOD)
   ‚úÖ Content meets PhD quality standards

5. MEDIA GENERATION
   ‚Üì
   [Step 3/6] Adding images...
   üñºÔ∏è  IMAGE GENERATION - Japanese Landscape
   Method: AI (DALL-E 3)
   ‚úÖ Image created: japanese_landscape.png

6. TABLE GENERATION
   ‚Üì
   [Step 4/6] Adding data tables...
   Generating table: Top Industries in Japan
   ‚úÖ Table generated with 5 rows, 3 columns

7. DOCUMENT ASSEMBLY
   ‚Üì
   [Step 5/6] Writing to file...
   Path: session_20251026_142835/documents/japan_20251026_142905.md
   ‚úÖ File written (14,582 bytes)

8. FINAL VALIDATION
   ‚Üì
   [Step 6/6] Final quality verification...
   Quality Score: 8.2/10
   Word Count: 1245
   Images: 1
   Tables: 1
   ‚úÖ Quality verification complete

9. USER NOTIFICATION
   ‚Üì
   ‚úÖ DOCUMENT GENERATION COMPLETE
   üìÑ File: japan_20251026_142905.md
   üìç Location: workspace/session_20251026_142835/documents/japan_20251026_142905.md
   üìä Words: 1245
   üéì Quality Score: 8.2/10 (GOOD)
   üñºÔ∏è  Images: 1
   üìà Tables: 1
```

## Error Handling and Recovery

### Detection Phase Failures

If topic extraction fails, the system provides diagnostic output and suggests rephrasing:

```
[üîç Detection] No specific task detected - falling back to chat
   Message: write something interesting...
   
Tip: Please specify a topic. Try: "write an essay about [topic]"
```

### Generation Phase Failures

API errors or timeout issues should trigger graceful degradation:

```python
try:
    content = self._call_llm_for_content(prompt)
except APIError as e:
    # Attempt fallback provider
    content = self._call_llm_for_content(prompt, provider='deepseek')
except Exception as e:
    # Use template content
    content = self._generate_template_content(topic)
```

### Quality Phase Failures

If content repeatedly fails quality review after maximum iterations:

```python
if iteration_count >= max_iterations:
    print(f"‚ö†Ô∏è  Maximum revision iterations reached")
    print(f"   Current score: {current_score}/10")
    print(f"   Proceeding with current version")
    # Save document despite lower quality
```

## Performance Optimization

### Caching Strategy

Frequently requested topics should cache generated outlines and common sections:

```python
cache_key = f"outline_{topic}_{document_type}"
if cache_key in self.plan_cache:
    return self.plan_cache[cache_key]
```

### Parallel Processing

Independent operations can execute concurrently:

```python
import asyncio

async def generate_media_parallel(media_specs):
    tasks = [generate_single_media(spec) for spec in media_specs]
    return await asyncio.gather(*tasks)
```

### Progressive Delivery

Stream content to user as sections complete rather than waiting for entire document:

```python
for section in sections:
    section_content = generate_section(section)
    print(f"‚úÖ Completed: {section['title']}")
    save_partial_document(section_content)
```

## Conclusion

The complete content generation pipeline transforms user requests into professional documents through a systematic, multi-stage process. Each stage has clearly defined responsibilities, inputs, and outputs, enabling robust error handling, quality control, and iterative improvement. The current implementation provides a solid foundation with detection, content generation, quality review, and file persistence operational. The recommended enhancements for planning, section-by-section generation, intelligent media placement, and LLM-generated tables will elevate the system to production-ready status capable of generating publication-quality documents autonomously.

**Current Status**:
- ‚úÖ Request detection and routing (COMPLETE)
- ‚ö†Ô∏è  Document planning (NEEDS IMPLEMENTATION)
- ‚úÖ Content generation (COMPLETE, needs enhancement)
- ‚úÖ Media generation (COMPLETE)
- ‚ö†Ô∏è  Table generation (PLACEHOLDER, needs implementation)
- ‚úÖ Document assembly (COMPLETE, needs enhancement)
- ‚úÖ Quality review (COMPLETE)
- ‚úÖ File persistence (COMPLETE)
- ‚úÖ Session management (COMPLETE)

**Next Priority**: Implement document planning stage to enable structured content generation.
